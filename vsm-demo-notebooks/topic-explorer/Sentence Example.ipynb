{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the `Corpus` objects to train and view a term frequency (TF) or \"word count\" model, a term frequency-inverse document frequency (tf-idf) model, the Latent Semantic Analysis (LSA) model, and view topics in the LDA models trained throught the topic explorer.\n",
    "\n",
    "To run the notebook, use the menu `Cell -> Run All` or use the play button for one cell at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we load the vsm module and import your corpus\n",
    "from vsm import *\n",
    "from corpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA models are automatically imported in the dictionary `lda_v[k]` where k is the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print topic_range\n",
    "k_val = topic_range[-1]\n",
    "v=lda_v[k_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v.topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentence Simialrity Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vsm.extensions.ldasentences import sim_sent_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, a helper to find the sentence IDs\n",
    "def find_sentence_ids(phrase):\n",
    "    ids = []\n",
    "    for sent_id, sentence in enumerate(c.sentences):\n",
    "        if phrase in sentence:\n",
    "            ids.append(sent_id)\n",
    "            \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use this to search for a particular phrase\n",
    "find_sentence_ids('Reason has previously become')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This allows us to view the sentence\n",
    "print c.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is how you get similarity for a particular sentence\n",
    "# If the distance is 0, it means that the topic distribution is identical for this model.\n",
    "tok_sents, orig_sents, sim_sents = sim_sent_sent(v, 0)\n",
    "sim_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# finding the whole passage for Axioms of Intuition: Part 1\n",
    "# First we find the first sentence of the proof\n",
    "print find_sentence_ids('All phenomena contain, as regards their form, an intuition in space and time, which lies a priori at the foundation of all without exception.')\n",
    "\n",
    "#Then the last sentence of the first section\n",
    "print find_sentence_ids('But in this case, no a priori synthetical cognition of them could be possible, consequently not through pure conceptions of space and the science which determines these conceptions, that is to say, geometry, would itself be impossible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first print all these sentences:\n",
    "print c.sentences[1664:1696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c.view_contexts('sentence', as_strings=True)[1664:1697]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# another way that you can get a list of all the numbers between 1664 and 1696 is the \"range()\" function\n",
    "list(range(1664,1697))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# looking for sentence similarity to a range of sentences\n",
    "tok_sents, orig_sents, sim_sents = sim_sent_sent(v, list(range(1664, 1697)), print_len=5, min_sent_len=5)\n",
    "sim_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
